<!DOCTYPE html>
<html lang="en">
    <head>
        <title>A Law of Robustness</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="https://unpkg.com/tachyons/css/tachyons.min.css">
        <style>
            body {
                font-family: monospace;
                color: #333;
                background-color: #faf9f6;
            }
            a {
                color: #6E5BAA;
                text-decoration: underline;
                transition: all 0.3s ease;
            }
            a:hover {
                opacity: 0.7;
            }
            .content-box {
                max-width: 700px;
            }
            .last-updated {
                font-size: 0.8rem;
                color: #888;
                text-align: right;
                margin-top: 2rem;
            }
            pre {
                margin: 0;
                padding: 0;
            }
            code {
                font-size: 75%;
            }
            pre code {
                margin: 0;
                background-color: #f0eee9;
                border: 1px solid #ccc;
                display: block;
                padding: 5px;
            }
        </style>
    </head>
    <body class="tl">
        <main class="pa4 center content-box mw7 lh-copy">
            <div class="mw6 ph1">
		    <p> During the spring, I took a discrete probability course (6.7720). This was one of the most interesting mathematics courses I've ever taken, second only to an amazing reading course on dynamical systems under Adam Kanigowski (<a href="https://www.math.umd.edu/~dolgop/DLT6.pdf">read this </a> if limit theorems for dynamical systems interests you!).  </p>

                <p> While I have no aspirations of becoming a theoretician (a life in academia has always been a non-starter), my time in the course allowed me to read a paper I had stored in my "papers to read" cache back in 2021: the Universal Law of Robustness paper by Sellke and Bubeck. To summarize: classically, models that interpolate (perfectly fit) their training data were expected to generalize poorly. However, they often perform well in practice, a phenomenon that led to Belkin et al.'s discovery of the "double descent" curve. In this paper, Sellke proposes a necessary condition for fitting that explains the emergence of this curve.</p>

		        <p> Back in 2021, I found the paper to be a tough read. However, after taking the course, I found it rather pleasant, with well-written and concise proofs.</p>

		        <p> As a final project, I wrote an exposition on this paper. This exposition, </p>

		        <ul>
			        <li> Outlines the main ideas/intuition behind the paper. </li>
			        <li> Presents some open questions. </li>
			        <li> Gives a short description of a recent extension. </li>
		        </ul>

		        <p> If you're interested in this robustness paper but struggle to read it and want a more hand wavy (intuition heavy) perspective on it, <a href="SP_Final_Project_blog.pdf"> read the exposition here</a>. </p>
            </div>
            
            <p class="pt3">
                <a href="../index.html">&larr; Back to musings</a>
            </p>
        </main>
    </body>
</html>